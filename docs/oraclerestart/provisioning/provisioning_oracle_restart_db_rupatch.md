# Provisioning an Oracle Restart Database with RU Patch on FileSystem

In this use case, the Oracle Grid Infrastructure and Oracle Restart Database are deployed automatically using Oracle Restart Controller. The responsefile is 
generated by the Oracle Restart Controller based on input parameters specified in the .yaml file.

This example uses `oraclerestart_prov_rupatch.yaml` to provision an Oracle Restart Database using Oracle Restart Controller with:

* 1 Node Oracle Restart
* Headless services for Oracle Restart
  * Oracle Restart node hostname
* Persistent volumes created automatically based on specified disks for Oracle Restart storage
* Software Persistent Volumes and Staged Software Persistent Volumes using the specified location on the corresponding worker nodes
* Namespace: `orestart`
* Staged Software location on the worker nodes is specified by `hostSwStageLocation` and we have copied the Grid Infrastructure and RDBMS Binaries to this location on the worker nodes
* Software location on the worker nodes is specified by `hostSwLocation`. The GI HOME and the RDBMS HOME in the Oracle Restart Pod will be mounted using this location on the worker node.
* Directory where the **Release Update (RU) patch** has been unzipped as `ruPatchLocation`. This folder **must contain `PatchSearch.xml`**, which is used by the installer to detect and apply the patch. Example: `/scratch/software/19c/19.28/` 

In this example, 
  * We are using Oracle Restart Database slim image by building it from Git location(./https://orahub.oci.oraclecorp.com/rac-docker-dev/rac-docker-images/-/blob/master/OracleRealApplicationClusters/README.md#building-oracle-rac-database-container-slim-image) i.e. `localhost/oracle/database-rac:19.3.0-slim`. To use this in your in own environment, update the image value in the `oraclerestart_prov_rupatch.yaml` file to point to your own container registry base container image.
  * The disks on the worker nodes for the Oracle Restart storage are `/dev/oracleoci/oraclevdd` and `/dev/oracleoci/oraclevde`. 
  * Specify the size of these devices along with names using the parameter `disksBySize`. Size is by-default in GBs.

  
Use the file: [oraclerestart_prov_rupatch.yaml](./oraclerestart_prov_rupatch.yaml) for this use case as below:

1. Deploy the `oraclerestart_prov_rupatch.yaml` file:
    ```sh
    kubectl apply -f oraclerestart_prov_rupatch.yaml
    oraclerestart.database.oracle.com/oraclerestart-sample created
    ```
2. Check the status of the deployment:
    ```sh
    # Check the status of the Kubernetes Pods:    
    kubectl get all -n orestart

    # Check the logs of a particular pod. For example, to check status of pod "dbmc1-0":    
    kubectl exec -it pod/dbmc1-0 -n orestart -- bash -c "tail -f /tmp/orod/oracle_db_setup.log"
    ===============================
    ORACLE DATABASE IS READY TO USE
    ===============================
    ```
3. Check Details of Kubernetes CRD Object as in this [example](./orestart_rupatch_object.txt)
4. In this case, the port 1521 from the pod is mapped to port 30007 on the worker node. To make the connection from outside, you will need to open the port 30007 on the worker node for INGRESS.

Once done, you will be able to make an SQLPLUS database connection to this Oracle Restart Database from a remote client as below
```sh
bash-4.4$ sqlplus system/Oracle_23ai@//129.146.0.149:30007/PORCLCDB

SQL*Plus: Release 23.0.0.0.0 - for Oracle Cloud and Engineered Systems on Sat Jul 19 04:02:48 2025
Version 23.9.0.25.09
Copyright (c) 1982, 2025, Oracle.  All rights reserved.
Last Successful login time: Sat Jul 19 2025 00:20:14 +00:00
Connected to:
Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
Version 19.28.0.0.0
SQL>
SQL> set lines 200
SQL> col HOST_NAME format a40
SQL> select INSTANCE_NAME,HOST_NAME, DATABASE_TYPE from v$instance;
INSTANCE_NAME  HOST_NAME                                DATABASE_TYPE
---------------- ---------------------------------------- ---------------
PORCLCDB        dbmc1-0                                 SINGLE
```
